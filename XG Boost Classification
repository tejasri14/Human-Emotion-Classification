#importing libraries 

  import pandas as pd                                                   #pandas
  import numpy as np                                                    #numpy
  from sklearn.decomposition import PCA                                 #PCA
  from sklearn.model_selection import train_test_split                  #splitting test and train data
  conda install -c anaconda py-xgboost
  from xgboost.sklearn import XGBClassifier                             #XG Bosst Classifier
  import xgboost                                                        
  from sklearn.model_selection import GridSearchCV                      #Grid Search to find the best parameters
  from sklearn.metrics import accuracy_score                            #Accuracy
  import seaborn as sn                        
  import matplotlib.pyplot as plt
  from sklearn.metrics import confusion_matrix                          #Confusion Matrix

  data=pd.read_csv("C:/Users/Tejasri/Desktop/emotions.csv")

  emotion={"POSITIVE":1,"NEGATIVE":-1,"NEUTRAL":0}
  data["label"]=[emotion[item] for item in data["label"]]

  data["label"].value_counts()                                          #to chack if we have enough samples of each target
  X=data.iloc[:,:2548]
  y=data.iloc[:,2548:2549]

#According to the research paper, 40 features give the best accuracy
  features=PCA(n_components=40)
  principal_components=features.fit_transform(X)
  Data=pd.DataFrame(data=principal_components,columns=["one","two","three","four","five","six","seven","eight","nine","ten","eleven","twelve","thirteen","fourteen","fifteen","sixteen","seventeen","eighteen","nineteen","twenety","a","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p","q","t","v","w"])

#splitting data for testing and training
  train_train,train_test,y_train,y_test= train_test_split(Data,y,test_size=0.2,random_state=1)

#setting paramenters for Grid search
  params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],
            'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}
  xgb = XGBClassifier(nthread=-1)
  grid = GridSearchCV(xgb, params)
  grid.fit(train_train,y_train)


  y_pred=grid.best_estimator_.predict(train_test)
  y_pred=y_pred.tolist()
  y_test=y_test["label"].tolist()
  print(accuracy_score(y_test,y_pred))

#generating Confusion Matrix
  cm=confusion_matrix(y_test,y_pred)
  conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:Neg','Predicted:Pos', 'Predicted:Neu'],index=['Actual:-1','Actual:1','Actual:0'])
  plt.figure(figsize = (8,5))
  sn.heatmap(conf_matrix, annot=True,fmt='d',cmap="YlGnBu")
